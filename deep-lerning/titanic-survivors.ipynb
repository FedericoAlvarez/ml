{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try to predict titanic survivors with basic deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First: Import and clean dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
       "      <td>female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PP 9549</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>G6</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bonnell, Miss. Elizabeth</td>\n",
       "      <td>female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113783</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>C103</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Beesley, Mr. Lawrence</td>\n",
       "      <td>male</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248698</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>D56</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sloper, Mr. William Thompson</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113788</td>\n",
       "      <td>35.5000</td>\n",
       "      <td>A6</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Fortune, Mr. Charles Alexander</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>19950</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Harper, Mrs. Henry Sleeper (Myna Haxtun)</td>\n",
       "      <td>female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17572</td>\n",
       "      <td>76.7292</td>\n",
       "      <td>D33</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Ostby, Mr. Engelhart Cornelius</td>\n",
       "      <td>male</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>113509</td>\n",
       "      <td>61.9792</td>\n",
       "      <td>B30</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PassengerId  Survived  Pclass  \\\n",
       "1             2         1       1   \n",
       "3             4         1       1   \n",
       "6             7         0       1   \n",
       "10           11         1       3   \n",
       "11           12         1       1   \n",
       "21           22         1       2   \n",
       "23           24         1       1   \n",
       "27           28         0       1   \n",
       "52           53         1       1   \n",
       "54           55         0       1   \n",
       "\n",
       "                                                 Name     Sex   Age  SibSp  \\\n",
       "1   Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "3        Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "6                             McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "10                    Sandstrom, Miss. Marguerite Rut  female   4.0      1   \n",
       "11                           Bonnell, Miss. Elizabeth  female  58.0      0   \n",
       "21                              Beesley, Mr. Lawrence    male  34.0      0   \n",
       "23                       Sloper, Mr. William Thompson    male  28.0      0   \n",
       "27                     Fortune, Mr. Charles Alexander    male  19.0      3   \n",
       "52           Harper, Mrs. Henry Sleeper (Myna Haxtun)  female  49.0      1   \n",
       "54                     Ostby, Mr. Engelhart Cornelius    male  65.0      0   \n",
       "\n",
       "    Parch    Ticket      Fare        Cabin Embarked  \n",
       "1       0  PC 17599   71.2833          C85        C  \n",
       "3       0    113803   53.1000         C123        S  \n",
       "6       0     17463   51.8625          E46        S  \n",
       "10      1   PP 9549   16.7000           G6        S  \n",
       "11      0    113783   26.5500         C103        S  \n",
       "21      0    248698   13.0000          D56        S  \n",
       "23      0    113788   35.5000           A6        S  \n",
       "27      2     19950  263.0000  C23 C25 C27        S  \n",
       "52      0  PC 17572   76.7292          D33        C  \n",
       "54      1    113509   61.9792          B30        C  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "input_file = \"train.csv\"\n",
    "df = pd.read_csv(input_file, header = 0)\n",
    "\n",
    "df = df.dropna() \n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove unnecesary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.5000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>76.7292</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>61.9792</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Survived  Pclass     Sex   Age  SibSp  Parch      Fare Embarked\n",
       "1          1       1  female  38.0      1      0   71.2833        C\n",
       "3          1       1  female  35.0      1      0   53.1000        S\n",
       "6          0       1    male  54.0      0      0   51.8625        S\n",
       "10         1       3  female   4.0      1      1   16.7000        S\n",
       "11         1       1  female  58.0      0      0   26.5500        S\n",
       "21         1       2    male  34.0      0      0   13.0000        S\n",
       "23         1       1    male  28.0      0      0   35.5000        S\n",
       "27         0       1    male  19.0      3      2  263.0000        S\n",
       "52         1       1  female  49.0      1      0   76.7292        C\n",
       "54         0       1    male  65.0      0      1   61.9792        C"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop('Name', 1)\n",
    "df = df.drop('Ticket', 1)\n",
    "df = df.drop('Cabin', 1)\n",
    "df = df.drop('PassengerId', 1)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.5000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>76.7292</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>61.9792</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Pclass     Sex   Age  SibSp  Parch      Fare Embarked\n",
       "1        1  female  38.0      1      0   71.2833        C\n",
       "3        1  female  35.0      1      0   53.1000        S\n",
       "6        1    male  54.0      0      0   51.8625        S\n",
       "10       3  female   4.0      1      1   16.7000        S\n",
       "11       1  female  58.0      0      0   26.5500        S\n",
       "21       2    male  34.0      0      0   13.0000        S\n",
       "23       1    male  28.0      0      0   35.5000        S\n",
       "27       1    male  19.0      3      2  263.0000        S\n",
       "52       1  female  49.0      1      0   76.7292        C\n",
       "54       1    male  65.0      0      1   61.9792        C"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop('Survived', axis = 1)\n",
    "y = df[['Survived']]\n",
    "\n",
    "X.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode categorical variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.    ,   1.    ,   1.    ,   0.    ,   0.    ,   1.    ,\n",
       "         38.    ,   1.    ,   0.    ,  71.2833],\n",
       "       [  0.    ,   1.    ,   0.    ,   1.    ,   0.    ,   1.    ,\n",
       "         35.    ,   1.    ,   0.    ,  53.1   ],\n",
       "       [  1.    ,   0.    ,   0.    ,   1.    ,   0.    ,   1.    ,\n",
       "         54.    ,   0.    ,   0.    ,  51.8625],\n",
       "       [  0.    ,   1.    ,   0.    ,   1.    ,   0.    ,   3.    ,\n",
       "          4.    ,   1.    ,   1.    ,  16.7   ],\n",
       "       [  0.    ,   1.    ,   0.    ,   1.    ,   0.    ,   1.    ,\n",
       "         58.    ,   0.    ,   0.    ,  26.55  ],\n",
       "       [  1.    ,   0.    ,   0.    ,   1.    ,   0.    ,   2.    ,\n",
       "         34.    ,   0.    ,   0.    ,  13.    ],\n",
       "       [  1.    ,   0.    ,   0.    ,   1.    ,   0.    ,   1.    ,\n",
       "         28.    ,   0.    ,   0.    ,  35.5   ],\n",
       "       [  1.    ,   0.    ,   0.    ,   1.    ,   0.    ,   1.    ,\n",
       "         19.    ,   3.    ,   2.    , 263.    ],\n",
       "       [  0.    ,   1.    ,   1.    ,   0.    ,   0.    ,   1.    ,\n",
       "         49.    ,   1.    ,   0.    ,  76.7292],\n",
       "       [  1.    ,   0.    ,   1.    ,   0.    ,   0.    ,   1.    ,\n",
       "         65.    ,   0.    ,   1.    ,  61.9792]])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colT = ColumnTransformer(\n",
    "   [(\"dummy_col\", OneHotEncoder(categories=[['male', 'female'],\n",
    "                                            ['C', 'S', 'Q']]), [1,6])\n",
    "   ], remainder=\"passthrough\")\n",
    "\n",
    "\n",
    "X = colT.fit_transform(X)\n",
    "X[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove dummy variables\n",
    "Column nro 1 and 2 (0 is for sex and 2 for harvour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.    ,  0.    ,  0.    ,  1.    , 38.    ,  1.    ,  0.    ,\n",
       "        71.2833],\n",
       "       [ 1.    ,  1.    ,  0.    ,  1.    , 35.    ,  1.    ,  0.    ,\n",
       "        53.1   ],\n",
       "       [ 0.    ,  1.    ,  0.    ,  1.    , 54.    ,  0.    ,  0.    ,\n",
       "        51.8625]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X [:, [1,3,4,5,6,7,8,9]]\n",
    "X[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.03901177, -1.31580518, -0.10511767, ...,  0.83362754,\n",
       "        -0.63172982, -0.0971798 ],\n",
       "       [ 1.03901177,  0.75999093, -0.10511767, ...,  0.83362754,\n",
       "        -0.63172982, -0.3359971 ],\n",
       "       [-0.96245301,  0.75999093, -0.10511767, ..., -0.7230443 ,\n",
       "        -0.63172982, -0.35225028],\n",
       "       ...,\n",
       "       [ 1.03901177, -1.31580518, -0.10511767, ..., -0.7230443 ,\n",
       "         0.69708118,  0.05878503],\n",
       "       [ 1.03901177,  0.75999093, -0.10511767, ..., -0.7230443 ,\n",
       "        -0.63172982, -0.63938976],\n",
       "       [-0.96245301, -1.31580518, -0.10511767, ..., -0.7230443 ,\n",
       "        -0.63172982, -0.63938976]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 0.6919 - acc: 0.6557\n",
      "Epoch 2/100\n",
      "183/183 [==============================] - 0s 233us/step - loss: 0.6893 - acc: 0.6721\n",
      "Epoch 3/100\n",
      "183/183 [==============================] - 0s 219us/step - loss: 0.6866 - acc: 0.6721\n",
      "Epoch 4/100\n",
      "183/183 [==============================] - 0s 217us/step - loss: 0.6831 - acc: 0.6721\n",
      "Epoch 5/100\n",
      "183/183 [==============================] - 0s 228us/step - loss: 0.6790 - acc: 0.6721\n",
      "Epoch 6/100\n",
      "183/183 [==============================] - 0s 225us/step - loss: 0.6735 - acc: 0.6721\n",
      "Epoch 7/100\n",
      "183/183 [==============================] - 0s 227us/step - loss: 0.6665 - acc: 0.6721\n",
      "Epoch 8/100\n",
      "183/183 [==============================] - 0s 220us/step - loss: 0.6574 - acc: 0.6721\n",
      "Epoch 9/100\n",
      "183/183 [==============================] - 0s 223us/step - loss: 0.6442 - acc: 0.6721\n",
      "Epoch 10/100\n",
      "183/183 [==============================] - 0s 222us/step - loss: 0.6304 - acc: 0.6721\n",
      "Epoch 11/100\n",
      "183/183 [==============================] - 0s 234us/step - loss: 0.6120 - acc: 0.6721\n",
      "Epoch 12/100\n",
      "183/183 [==============================] - 0s 220us/step - loss: 0.5923 - acc: 0.6721\n",
      "Epoch 13/100\n",
      "183/183 [==============================] - 0s 225us/step - loss: 0.5723 - acc: 0.6721\n",
      "Epoch 14/100\n",
      "183/183 [==============================] - 0s 230us/step - loss: 0.5528 - acc: 0.6721\n",
      "Epoch 15/100\n",
      "183/183 [==============================] - 0s 226us/step - loss: 0.5349 - acc: 0.6721\n",
      "Epoch 16/100\n",
      "183/183 [==============================] - 0s 231us/step - loss: 0.5198 - acc: 0.6831\n",
      "Epoch 17/100\n",
      "183/183 [==============================] - 0s 219us/step - loss: 0.5066 - acc: 0.7268\n",
      "Epoch 18/100\n",
      "183/183 [==============================] - 0s 216us/step - loss: 0.4955 - acc: 0.7541\n",
      "Epoch 19/100\n",
      "183/183 [==============================] - 0s 225us/step - loss: 0.4853 - acc: 0.7541\n",
      "Epoch 20/100\n",
      "183/183 [==============================] - 0s 228us/step - loss: 0.4774 - acc: 0.7596\n",
      "Epoch 21/100\n",
      "183/183 [==============================] - 0s 222us/step - loss: 0.4706 - acc: 0.7596\n",
      "Epoch 22/100\n",
      "183/183 [==============================] - 0s 217us/step - loss: 0.4646 - acc: 0.7760\n",
      "Epoch 23/100\n",
      "183/183 [==============================] - 0s 232us/step - loss: 0.4597 - acc: 0.7869\n",
      "Epoch 24/100\n",
      "183/183 [==============================] - 0s 228us/step - loss: 0.4546 - acc: 0.7760\n",
      "Epoch 25/100\n",
      "183/183 [==============================] - 0s 227us/step - loss: 0.4509 - acc: 0.7869\n",
      "Epoch 26/100\n",
      "183/183 [==============================] - 0s 239us/step - loss: 0.4482 - acc: 0.7869\n",
      "Epoch 27/100\n",
      "183/183 [==============================] - 0s 238us/step - loss: 0.4451 - acc: 0.7869\n",
      "Epoch 28/100\n",
      "183/183 [==============================] - 0s 228us/step - loss: 0.4428 - acc: 0.7814\n",
      "Epoch 29/100\n",
      "183/183 [==============================] - 0s 234us/step - loss: 0.4409 - acc: 0.7923\n",
      "Epoch 30/100\n",
      "183/183 [==============================] - 0s 262us/step - loss: 0.4388 - acc: 0.7923\n",
      "Epoch 31/100\n",
      "183/183 [==============================] - 0s 261us/step - loss: 0.4374 - acc: 0.7869\n",
      "Epoch 32/100\n",
      "183/183 [==============================] - 0s 240us/step - loss: 0.4360 - acc: 0.7869\n",
      "Epoch 33/100\n",
      "183/183 [==============================] - 0s 245us/step - loss: 0.4351 - acc: 0.7869\n",
      "Epoch 34/100\n",
      "183/183 [==============================] - 0s 277us/step - loss: 0.4337 - acc: 0.7923\n",
      "Epoch 35/100\n",
      "183/183 [==============================] - 0s 277us/step - loss: 0.4331 - acc: 0.7923\n",
      "Epoch 36/100\n",
      "183/183 [==============================] - 0s 265us/step - loss: 0.4318 - acc: 0.7923\n",
      "Epoch 37/100\n",
      "183/183 [==============================] - 0s 257us/step - loss: 0.4310 - acc: 0.7869\n",
      "Epoch 38/100\n",
      "183/183 [==============================] - 0s 267us/step - loss: 0.4304 - acc: 0.7923\n",
      "Epoch 39/100\n",
      "183/183 [==============================] - 0s 248us/step - loss: 0.4293 - acc: 0.7923\n",
      "Epoch 40/100\n",
      "183/183 [==============================] - 0s 263us/step - loss: 0.4285 - acc: 0.7923\n",
      "Epoch 41/100\n",
      "183/183 [==============================] - 0s 258us/step - loss: 0.4279 - acc: 0.7869\n",
      "Epoch 42/100\n",
      "183/183 [==============================] - 0s 267us/step - loss: 0.4265 - acc: 0.7923\n",
      "Epoch 43/100\n",
      "183/183 [==============================] - 0s 265us/step - loss: 0.4266 - acc: 0.7923\n",
      "Epoch 44/100\n",
      "183/183 [==============================] - 0s 267us/step - loss: 0.4262 - acc: 0.7869\n",
      "Epoch 45/100\n",
      "183/183 [==============================] - 0s 262us/step - loss: 0.4255 - acc: 0.7814\n",
      "Epoch 46/100\n",
      "183/183 [==============================] - 0s 270us/step - loss: 0.4248 - acc: 0.7760\n",
      "Epoch 47/100\n",
      "183/183 [==============================] - 0s 290us/step - loss: 0.4237 - acc: 0.7923\n",
      "Epoch 48/100\n",
      "183/183 [==============================] - 0s 269us/step - loss: 0.4233 - acc: 0.7869\n",
      "Epoch 49/100\n",
      "183/183 [==============================] - 0s 262us/step - loss: 0.4230 - acc: 0.7869\n",
      "Epoch 50/100\n",
      "183/183 [==============================] - 0s 276us/step - loss: 0.4223 - acc: 0.7923\n",
      "Epoch 51/100\n",
      "183/183 [==============================] - 0s 288us/step - loss: 0.4220 - acc: 0.7869\n",
      "Epoch 52/100\n",
      "183/183 [==============================] - 0s 284us/step - loss: 0.4219 - acc: 0.7978\n",
      "Epoch 53/100\n",
      "183/183 [==============================] - 0s 249us/step - loss: 0.4212 - acc: 0.7923\n",
      "Epoch 54/100\n",
      "183/183 [==============================] - 0s 263us/step - loss: 0.4206 - acc: 0.7923\n",
      "Epoch 55/100\n",
      "183/183 [==============================] - 0s 248us/step - loss: 0.4203 - acc: 0.7923\n",
      "Epoch 56/100\n",
      "183/183 [==============================] - 0s 236us/step - loss: 0.4204 - acc: 0.7923\n",
      "Epoch 57/100\n",
      "183/183 [==============================] - 0s 249us/step - loss: 0.4202 - acc: 0.7923\n",
      "Epoch 58/100\n",
      "183/183 [==============================] - 0s 254us/step - loss: 0.4196 - acc: 0.7923\n",
      "Epoch 59/100\n",
      "183/183 [==============================] - 0s 246us/step - loss: 0.4194 - acc: 0.7923\n",
      "Epoch 60/100\n",
      "183/183 [==============================] - 0s 252us/step - loss: 0.4187 - acc: 0.7869\n",
      "Epoch 61/100\n",
      "183/183 [==============================] - 0s 243us/step - loss: 0.4183 - acc: 0.7923\n",
      "Epoch 62/100\n",
      "183/183 [==============================] - 0s 246us/step - loss: 0.4179 - acc: 0.7923\n",
      "Epoch 63/100\n",
      "183/183 [==============================] - 0s 246us/step - loss: 0.4175 - acc: 0.7869\n",
      "Epoch 64/100\n",
      "183/183 [==============================] - 0s 243us/step - loss: 0.4171 - acc: 0.7869\n",
      "Epoch 65/100\n",
      "183/183 [==============================] - 0s 252us/step - loss: 0.4167 - acc: 0.7869\n",
      "Epoch 66/100\n",
      "183/183 [==============================] - 0s 258us/step - loss: 0.4162 - acc: 0.7923\n",
      "Epoch 67/100\n",
      "183/183 [==============================] - 0s 264us/step - loss: 0.4160 - acc: 0.7923\n",
      "Epoch 68/100\n",
      "183/183 [==============================] - 0s 259us/step - loss: 0.4160 - acc: 0.7923\n",
      "Epoch 69/100\n",
      "183/183 [==============================] - 0s 248us/step - loss: 0.4154 - acc: 0.7923\n",
      "Epoch 70/100\n",
      "183/183 [==============================] - 0s 257us/step - loss: 0.4152 - acc: 0.7978\n",
      "Epoch 71/100\n",
      "183/183 [==============================] - 0s 237us/step - loss: 0.4146 - acc: 0.7923\n",
      "Epoch 72/100\n",
      "183/183 [==============================] - 0s 246us/step - loss: 0.4146 - acc: 0.7978\n",
      "Epoch 73/100\n",
      "183/183 [==============================] - 0s 254us/step - loss: 0.4142 - acc: 0.7978\n",
      "Epoch 74/100\n",
      "183/183 [==============================] - 0s 259us/step - loss: 0.4136 - acc: 0.7978\n",
      "Epoch 75/100\n",
      "183/183 [==============================] - 0s 233us/step - loss: 0.4133 - acc: 0.7869\n",
      "Epoch 76/100\n",
      "183/183 [==============================] - 0s 251us/step - loss: 0.4131 - acc: 0.7923\n",
      "Epoch 77/100\n",
      "183/183 [==============================] - 0s 261us/step - loss: 0.4129 - acc: 0.7923\n",
      "Epoch 78/100\n",
      "183/183 [==============================] - 0s 274us/step - loss: 0.4127 - acc: 0.7923\n",
      "Epoch 79/100\n",
      "183/183 [==============================] - 0s 282us/step - loss: 0.4120 - acc: 0.7978\n",
      "Epoch 80/100\n",
      "183/183 [==============================] - 0s 254us/step - loss: 0.4119 - acc: 0.7978\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/183 [==============================] - 0s 250us/step - loss: 0.4122 - acc: 0.7869\n",
      "Epoch 82/100\n",
      "183/183 [==============================] - 0s 258us/step - loss: 0.4119 - acc: 0.7978\n",
      "Epoch 83/100\n",
      "183/183 [==============================] - 0s 261us/step - loss: 0.4114 - acc: 0.7978\n",
      "Epoch 84/100\n",
      "183/183 [==============================] - 0s 264us/step - loss: 0.4109 - acc: 0.7978\n",
      "Epoch 85/100\n",
      "183/183 [==============================] - 0s 268us/step - loss: 0.4114 - acc: 0.7923\n",
      "Epoch 86/100\n",
      "183/183 [==============================] - 0s 264us/step - loss: 0.4110 - acc: 0.7978\n",
      "Epoch 87/100\n",
      "183/183 [==============================] - 0s 261us/step - loss: 0.4107 - acc: 0.7978\n",
      "Epoch 88/100\n",
      "183/183 [==============================] - 0s 266us/step - loss: 0.4104 - acc: 0.7923\n",
      "Epoch 89/100\n",
      "183/183 [==============================] - 0s 261us/step - loss: 0.4101 - acc: 0.7978\n",
      "Epoch 90/100\n",
      "183/183 [==============================] - 0s 253us/step - loss: 0.4104 - acc: 0.7978\n",
      "Epoch 91/100\n",
      "183/183 [==============================] - 0s 248us/step - loss: 0.4096 - acc: 0.8033\n",
      "Epoch 92/100\n",
      "183/183 [==============================] - 0s 246us/step - loss: 0.4095 - acc: 0.7978\n",
      "Epoch 93/100\n",
      "183/183 [==============================] - 0s 225us/step - loss: 0.4097 - acc: 0.7978\n",
      "Epoch 94/100\n",
      "183/183 [==============================] - 0s 227us/step - loss: 0.4094 - acc: 0.7978\n",
      "Epoch 95/100\n",
      "183/183 [==============================] - 0s 258us/step - loss: 0.4088 - acc: 0.7978\n",
      "Epoch 96/100\n",
      "183/183 [==============================] - 0s 269us/step - loss: 0.4088 - acc: 0.7978\n",
      "Epoch 97/100\n",
      "183/183 [==============================] - 0s 264us/step - loss: 0.4093 - acc: 0.7978\n",
      "Epoch 98/100\n",
      "183/183 [==============================] - 0s 262us/step - loss: 0.4085 - acc: 0.7978\n",
      "Epoch 99/100\n",
      "183/183 [==============================] - 0s 265us/step - loss: 0.4086 - acc: 0.7978\n",
      "Epoch 100/100\n",
      "183/183 [==============================] - 0s 260us/step - loss: 0.4082 - acc: 0.8033\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a261f7e80>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(units = 4, kernel_initializer = 'uniform', activation = 'relu', input_dim = 8))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 4, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(X_train, y, batch_size = 10, epochs = 100)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_test_file = \"test.csv\"\n",
    "df_test = pd.read_csv(input_file, header = 0)\n",
    "df_test = df_test.dropna() \n",
    "\n",
    "df_test = df_test.drop('Name', 1)\n",
    "df_test = df_test.drop('Ticket', 1)\n",
    "df_test = df_test.drop('Cabin', 1)\n",
    "df_test = df_test.drop('PassengerId', 1)\n",
    "\n",
    "X_test = df_test.drop('Survived', axis = 1)\n",
    "y_test = df_test[['Survived']]\n",
    "\n",
    "X_test = colT.fit_transform(X_test)\n",
    "X_test = X_test [:, [1,3,4,5,6,7,8,9]]\n",
    "\n",
    "X_test_train = sc.fit_transform(X_test)\n",
    "\n",
    "y_pred = classifier.predict(X_test_train)\n",
    "y_pred = (y_pred > 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 43,  17],\n",
       "       [ 19, 104]])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8032786885245902"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = (cm[0][0] + cm[1][1]) / y_test.size\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
